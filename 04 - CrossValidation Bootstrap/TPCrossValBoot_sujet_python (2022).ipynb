{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Analyse-des-performances-sur-les-données-de-Auto-Data-Set\" data-toc-modified-id=\"Analyse-des-performances-sur-les-données-de-Auto-Data-Set-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Analyse des performances sur les données de <em>Auto Data Set</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Utilisation-d'un-ensemble-de-validation---Train/test-split\" data-toc-modified-id=\"Utilisation-d'un-ensemble-de-validation---Train/test-split-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Utilisation d'un ensemble de validation - Train/test split</a></span></li><li><span><a href=\"#Utilisation-de-la-validation-croisée\" data-toc-modified-id=\"Utilisation-de-la-validation-croisée-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Utilisation de la validation croisée</a></span></li></ul></li><li><span><a href=\"#Estimation-des-performances-d'un-modèle-de-régression-linéaire\" data-toc-modified-id=\"Estimation-des-performances-d'un-modèle-de-régression-linéaire-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Estimation des performances d'un modèle de régression linéaire</a></span></li><li><span><a href=\"#Exercices-supplémentaires-[optionnels!-et-en-R...]---Validation-sur-la-base-Default\" data-toc-modified-id=\"Exercices-supplémentaires-[optionnels!-et-en-R...]---Validation-sur-la-base-Default-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exercices supplémentaires [optionnels! et en R...] - Validation sur la base <code>Default</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Modèle\" data-toc-modified-id=\"Modèle-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Modèle</a></span></li><li><span><a href=\"#Erreur-de-prédiction-par-validation.\" data-toc-modified-id=\"Erreur-de-prédiction-par-validation.-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Erreur de prédiction par validation.</a></span></li><li><span><a href=\"#Recommencer\" data-toc-modified-id=\"Recommencer-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Recommencer</a></span></li><li><span><a href=\"#Pertinence-d'une-nouvelle-variable----Validation\" data-toc-modified-id=\"Pertinence-d'une-nouvelle-variable----Validation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Pertinence d'une nouvelle variable -- Validation</a></span></li><li><span><a href=\"#Pertinence-d'une-nouvelle-variable----Validation-croisée\" data-toc-modified-id=\"Pertinence-d'une-nouvelle-variable----Validation-croisée-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Pertinence d'une nouvelle variable -- Validation croisée</a></span></li><li><span><a href=\"#Estimées-des-erreurs-standard-par-Bootstrap\" data-toc-modified-id=\"Estimées-des-erreurs-standard-par-Bootstrap-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Estimées des erreurs standard par Bootstrap</a></span><ul class=\"toc-item\"><li><span><a href=\"#Direct\" data-toc-modified-id=\"Direct-3.6.1\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>Direct</a></span></li><li><span><a href=\"#Par-bootstrap\" data-toc-modified-id=\"Par-bootstrap-3.6.2\"><span class=\"toc-item-num\">3.6.2&nbsp;&nbsp;</span>Par bootstrap</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exercices proposés dans cette séance de travaux pratiques sont adaptés de notre [livre de référence](http://www-bcf.usc.edu/~gareth/ISL/), chapitre 5, pp. 190-197 ainsi que des exercices plus avancés pp 199-201. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de vous lancer, vous installerez les packages utiles en lançant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score (sklearn > 0.2)\n",
    "from sklearn.cross_validation import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les datasets utiles peuvent être obtenus ici : [https://vincentarelbundock.github.io/Rdatasets/datasets.html](https://vincentarelbundock.github.io/Rdatasets/datasets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des performances sur les données de *Auto Data Set*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez les données contenues dans le fichier csv `Auto` dans un dataframe `df`, et éliminez les lignes contenant des valeurs inconnues (NA).  Examinez quelles sont les caractéristqies de ce dataframe. \n",
    "\n",
    "/!\\ Les NA sint désignés par '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(...\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilisera à nouveau les données `Auto`. \n",
    "Vous obtiendrez la description des variables par les lignes suivantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "with open(\"R_ Auto Data Set.html\",'r') as f: \n",
    "    display(HTML(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un ensemble de validation - Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous explorerez l'utilisation d'un ensemble de validation pour estimer l'erreur de prédiction pour différents modèles de régression ajustés sur les données `Auto`. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On utilisera la librairie scikit learn. Séparez votre dataframe en une matrice X des variables expicatives, et une réponse y. Vous chercherez à prédire `mpg` en fonction de `horsepower` (et plus tard de `horsepower` et de ses puissances)\n",
    "\n",
    "Vous utiliserez ensuite `train_test_split` pour séparer vos données en des données d'apprentissage et de test (validation). Vous prendrez 50% des données dans chaque ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[[...   # double crochet --> rend un dataframe\n",
    "# y = df[..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autre manière de procéder\n",
    "# idx = range(df.shape[0])\n",
    "# train_idx = np.random.choice(idx, size=int(round(df.shape[0]/2)))\n",
    "# test_idx = [index for index in idx if index not in train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Vous effectuerez ensuite une régression de `mpg` sur `horsepower`, en envisageant des régressions polynomiales, pour des degrés allant de 1 à 4. Utiliser la classe `LinearRegression()` de `sklearn.linear_model`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencez par une régression linéaire avec un ordre 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(..\n",
    "# print(\"score\", model.score(X_train,y_train))\n",
    "# eqm_train = mean_squared_error(...\n",
    "# eqm_test = mean_squared_error(...\n",
    "# print(\"Erreur moyenne (train) : \", eqm_train )\n",
    "# print(\"Erreur moyenne (test) : \", eqm_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ajouter des variables constituées par les puissances successives de `horsepower`, vous utiliserez la classe `PolynomialFeatures()`, que vous instancierez et dont vous utiliserez la méthode `fit_transform`.  Tester avec un ordre 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordre = 2\n",
    "# poly = PolynomialFeatures(degree=ordre)\n",
    "# X_poly = poly.fit_transform(df[['horsepower']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuez maintenant la régression linéaire avec un polynôme d'ordre 2 en `horsepower`, après avoir séparé vos données en train et test (comme précédemment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ...\n",
    "# model.fit(X_train,y_train)\n",
    "# print(\"score\", model.score(X_train,y_train))\n",
    "# eqm_train = mean_squared_error(...\n",
    "# eqm_test = mean_squared_error(...\n",
    "# print(\"Erreur moyenne (train) : \", eqm_train )\n",
    "# print(\"Erreur moyenne (test) : \", eqm_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On envisage maintenant des ordre allant de 0 à 12\n",
    "\n",
    "- pour chacun des degrés de polynôme, \n",
    "  - effectuer une régression avec le dataset Auto, **sur l'ensemble d'apprentissage** sélectionné question 1)\n",
    "  - tester les performances **sur la base de test** en calculant la moyenne de l'écart quadratique entre `mpg` et la valeur prédite. Méthode `predict`\n",
    "- tracer le résultat Erreur = f(ordre),  et/ou imprimer les performances obtenues\n",
    "- Effectuer l'ensemble de la procédure pour différentes valeurs du random seed, c'est-à-dire différents splits training/validation -- tracer l'ensemble des courbes obtenus\n",
    "- Quel degré faudrait-il adopter au vu de ces résultats, que penser de la stabilité des différentes estimées de l'erreur de prédiction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squelette\n",
    "ordremax = 12\n",
    "Eqm_test = np.zeros(shape=(ordremax))\n",
    "Eqm_test_cumul = np.zeros(shape=(ordremax))\n",
    "listeSeeds = np.random.choice(range(2000),size=10)\n",
    "for split in listeSeeds:\n",
    "    for order in range(ordremax):\n",
    "            # définir features poynomiaux\n",
    "            # split train/test\n",
    "        # modèle\n",
    "            #\n",
    "        # performances du modèle\n",
    "        \n",
    "            #Eqm_test[order] = eqm_test\n",
    "            # Eqm_test_cumul[order]  = Eqm_test_cumul[order]  + eqm_test\n",
    "        \n",
    "#     plt.plot(ordres, Eqm_test, '-o')  \n",
    "#     plt.xlabel(\"Ordre du modèle\")\n",
    "#     plt.ylabel(\"EQM sur l'ensemble de test\")\n",
    "#     plt.axis([0, 13, 15, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer la moyenne des erreurs (sur les différents splits), en fonction de l'ordre du modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(...\n",
    "# plt.xlabel(\"Ordre du modèle\")\n",
    "# plt.ylabel(\"EQM sur l'ensemble de test (moyenne)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas si simple de choisir le degré \"optimal\" lorque qu'on teste dfférents couples training/validation. le handicap est ici le faible nombre de données qui donne une très grande variabilité. Ce qui est net c'est que passer à un degré 2 donne une nette amélioration ; après c'est très variable suivant les différents assais. Dans ces conditions, on aura tendance à être très conservateur et à privilégier les ordres les plus faibles (donc le moins de variance).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de la validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser la validation croisée en Python, vous utiliserez tout simplement la méthode `cross_val_score` de la librairie `sklearn.cross_validation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold CV\n",
    "folds = 10\n",
    "\n",
    "# model = linear_model.LinearRegression()\n",
    "#cv_score = np.zeros((ordremax))\n",
    "\n",
    "for order in ordres:\n",
    "#     poly = ...\n",
    "#     X_poly = ...\n",
    "#     cv_score[order] = cross_val_score(model, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(ordres, -cv_score)\n",
    "# plt.xlabel(\"Ordre du modèle\")\n",
    "# plt.ylabel(\"EQM par validation croisée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation des performances d'un modèle de régression linéaire\n",
    "\n",
    "Comme on l'a vu en cours, il est possible d'utiliser le bootstrap afin de quantifier la qualité des estimées et prédictions des méthodes d'appprentissage statistique. Cela s'applique par exemple à la régression linéaire toute simple. On va considérer la régression habituelle  `mpg~horsepower` pour le dataset `Auto`, pour des degrés 1 et 2, et comparer les performances affichées à l'aide des formules explicites (connues dans ce cas simple), et l'évaluation numérique donnée par le bootstrap. \n",
    "\n",
    "1 -  Utiliser la fonction `lm` du TP sur la régression linéaire pour avoir effectuer la prédiction linéaire ci-dessus, en ayant accès aux performances (écart-type, p-values, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LinearRegression_in_Python_like_in_R import lm, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lm(...\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les coefficients du modèle peuvent être accédés, sous leur nom, par `model.params['nom_du_coeff']` (et `model.params` pour examiner ces coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 -  Créer une fonction `bootfn` qui prenne en entrée les données et un vecteur d'index et retourne les coefficients de la régression linéaire correspondante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bootfn(...\n",
    "#     model = ...\n",
    "#     return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 -  Utiliser la fonction `random.choice` pour rééchantillonner les données, puis calculer les estimées correspondantes par `bootfn`. Réitérer avec une autre valeur de seed. Comparer ces résultats. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(27)\n",
    "# I = np.random.choice(...  # Choix des index\n",
    "# bootfn(df, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(45)\n",
    "# I = np.random.choice(...  # Choix des index\n",
    "# bootfn(df, I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 -  Utiliser maintenant la fonction `boot` pour calculer un millier de ces estimées. Stocker les résultats dans un Dataframe.  Tracer les histogrammes correspondants, calculer les moyennes (`mean`)  et écarts-types (`std`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = 1000\n",
    "# coeffs_boot = pd.DataFrame(index=range(B), columns=['intercept', 'horsepower', 'horsepower**2'])\n",
    "\n",
    "# for b in range(B):\n",
    "#     I = np.random.choice(... # Choix des index\n",
    "#     \n",
    "#     coeffs_boot.iloc[b] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import cycle\n",
    "# c = cycle(['c', 'r', 'b', 'g'])\n",
    "\n",
    "# for col in coeffs_boot.columns:\n",
    "#     plt.figure()\n",
    "#     plt.hist(coeffs_boot[col].values.astype(float), color=next(c))\n",
    "#     plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_boot.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_boot.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Comparer ces résultats à ceux qu'on relève sur le résumé `summary` de la fonction `lm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation sur la base `Default`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base `Default` est un exemple célèbre de jeu de données pour un problème de classification.\n",
    "On utilisera ici une régression logistique. On estimera l'erreur de prédiction en utilisant un ensemble de validation, puis on testera l'importance des variables dans le modèle. Enfin, on estimera les statistiques sur les coefficients par bootstrap. \n",
    "\n",
    "## Modèle \n",
    "Charger la base defaut, fichier `default.csv`, choisir un seed, et apprendre un modèle de régression logistique pour `default~income+balance` (donc sans `student`). Afficher les résultats.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "#\n",
    "from GLMRegression_in_Python_like_in_R import GLMsummary, glm_residplot\n",
    "from LinearRegression_in_Python_like_in_R import lm, summary, vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprendre une régression logistique pour prédire `default` en fonction des autres variables et afficher les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_default = smf.glm(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erreur de prédiction par validation. \n",
    "\n",
    "Estimez l'erreur de prédiction pour ce modèle. Pour cela :\n",
    "\n",
    "1. Séparer les données en un ensemble d'apprentissage et un ensemble de validation (train=3/4 des données, test=le 1/4 restant)\n",
    "2. Apprendre le modèle\n",
    "3. Calculer les prédictions sur la base de test, et le taux d'erreur en seuillant la probabilité a posteriori à 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "Train, Test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "glm_default = smf.glm(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "probas_preds = ...\n",
    "preds = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erreur = 1 - accuracy\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommencer\n",
    "\n",
    "Répéter le processus précédent un certain nombre de fois (par exemple 300 fois), en utilisant différentes segmentations train-test des données. Commenter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 300\n",
    "Seeds = np.random.randint(0,10000, M)\n",
    "Erreur = np.zeros(M)\n",
    "for k, seed in enumerate(Seeds):\n",
    "    ...\n",
    "    Erreur[k] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pertinence d'une nouvelle variable -- Validation\n",
    "\n",
    "Considérons maintenant un modèle qui prédit la probabilité de défaut à partir de  income, balance, et d'une variable catégorielle sur student. Estimer le taux d'erreur sur un ensemble validation, pour plusieurs ensembles. Commenter sur l'utilité d'inclure ou non la variable student ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 300\n",
    "Seeds = np.random.randint(0,10000, M)\n",
    "Erreur = np.zeros(M)\n",
    "for k, seed in enumerate(Seeds):\n",
    "\n",
    "    ...\n",
    "print(np.mean(Erreur))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne semble pas qu'ajouter cette variable soit complètement pertinent car le taux d'erreur moyen est un peu supérieur... Mais cet effet reste faible, et à l'intérieur de l'intervalle de confiance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pertinence d'une nouvelle variable -- Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuer la même étude que précédemment, mais en évaluant les performances par validation croisée. Que concluerait-on cette fois ? Comment expliquer les différences éventuelles entre les performances ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser la validation croisée de sklearn sous Python, vous devrez aussi définir l'estimateur à partir de la classe LogisticRegression, ainsi qu'encoder la variable catégorielle `student`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[\"student_enc\"] = D[\"student\"].replace({\"No\":0, \"Yes\":1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sans student\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=100000)\n",
    "X = ...\n",
    "y = ... \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec student\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=100000)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci, il semble que l'on devrait garder Student ; mais encore une fois la différence est extrèmement faible. Les différences de performances entre l'approche validation et la validation croisée viennent du fait que dans la validation croisée, on utilise un apprentissage sur plus de données. Donc un modèle mieux appris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimées des erreurs standard par Bootstrap\n",
    "\n",
    "On poursuit avec la régression logistique et les données `Default`. On va maintenant comparer les erreurs standard sur le coefficients soit calculées analytiquement (et lues sur la sortie de `glm`), soit en utilisant un bootstrap. \n",
    "\n",
    "### Direct\n",
    "En utilisant `summary()` (ou `GLMsummary`) et `glm()`, déterminez les erreurs standards sur les coefficients associées à `income` `balance` dans une régression logistique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_default = smf.glm(\"default ~ balance + income\", \n",
    "                      D, family=sm.families.Binomial())\n",
    "\n",
    "res = glm_default.fit()\n",
    "GLMsummary(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par bootstrap\n",
    "\n",
    "1.  Écrire une fonction `boot.fn()` ou `bootfn`sous Python, qui reçoit `Default` ainsi qu'un index des observations et rend les estimées des coefficients pour  income et balance.\n",
    "2. Utiliser le bootstrap pour calculer les erreurs standard. Comparer avec les résultats précédents et commenter..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootfn(data, index):\n",
    "    model = ...\n",
    "    return model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1000\n",
    "coeffs_boot = pd.DataFrame(index=range(B), columns=['intercept', 'balance', 'income'])\n",
    "\n",
    "for b in range(B):\n",
    "    ...\n",
    "coeffs_boot.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les statistiques bootstrap :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(coeffs_boot, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(coeffs_boot, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients obtenus par le calcul analytique (possible ici) dans statsmodels\n",
    "res.bse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Et le résumé total\n",
    "GLMsummary(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "## \n",
    "## ORDINARY NONPARAMETRIC BOOTSTRAP\n",
    "## \n",
    "## \n",
    "## Call:\n",
    "## boot(data = Default, statistic = boot.fn, R = 1000)\n",
    "## \n",
    "## \n",
    "## Bootstrap Statistics :\n",
    "##       original     bias    std. error\n",
    "## t1* -1.154e+01 -8.008e-03   4.239e-01\n",
    "## t2*  2.081e-05  5.871e-08   4.583e-06\n",
    "## t3*  5.647e-03  2.300e-06   2.268e-04\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les estimées bootstrap sont très proches des valeurs fournies par `summary`. C'est bon signe !"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interactive_sols": {
   "cbx_id": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "ctrl-e",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "fr",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {
    "height": "300px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "415px",
    "left": "0px",
    "right": "938.011px",
    "top": "105px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "left": "1438.38px",
   "right": "21.6167px",
   "top": "124px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
