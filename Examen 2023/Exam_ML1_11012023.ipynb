{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP noté \"Machine Learning 1\" <a class=\"tocSkip\">\n",
    "11 janvier 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données proposées dans ce sujet sont des données synthétiques qui nous permettront d'examiner et mettre en oeuvre plusieurs des méthodes rencontrées dans l'unité. Ce sujet traitera ainsi de\n",
    "\n",
    "- régression de Poisson et régression linéaire\n",
    "- clustering (avec KMeans)\n",
    "- discrimination avec une régression logistique\n",
    "- estimation des performances par validation croisée\n",
    "- estimation d'incertitudes par bootstrap\n",
    "\n",
    "**Instructions** \n",
    "\n",
    "- répondre aux questions en utilisant _le langage de votre choix_, soit dans un Notebook Jupyter, soit dans un notebook Rstudio\n",
    "- vous ferez les calculs et tracerez les figures demandées. Vous insèrerez vos commentaires dans une cellule markdown/texte. _**Il est impératif de commenter ce que vous faites, pourquoi, et les résultats que vous obtenez ; le code seul ne vous rapportera qu'un peu plus de la moitié des points.**_  \n",
    "- vous pouvez même utiliser plusieurs langages si vous le souhaitez\n",
    "- tous documents autorisés\n",
    "- interdiction de communiquer avec d'autres intelligences, humaines ou artificielles. \n",
    "- en fin de session, vous rendrez votre notebook en le téléversant sur icampus\n",
    "\n",
    "\n",
    "**Les parties 2, 3, 4, 5 (partiellement) sont indépendantes** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Charger le fichier `Data_2023.csv`.Vous appellerez `df` le dataframe.  \n",
    "- Combien ce fichier contient-il d'exemples, de variables ? \n",
    "- Quelles peuvent être les variables catégorielles ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T14:26:38.531634600Z",
     "start_time": "2024-01-06T14:26:37.618498700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T14:26:38.565858100Z",
     "start_time": "2024-01-06T14:26:38.523202300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         v1 v2        v3  v4  v5   v6  v7  v8  v9  r\n0 -5.244266  A -2.544469 -12   0  0.0  -7 -19   8  0\n1  6.000000  A  4.922793   4   0  NaN   6  11  10  0\n2 -7.882469  B  0.087773 -10   0  0.0 -11 -20   8  1\n3 -7.155857  A -0.713578 -13   0  1.0 -10 -24   7  1\n4  2.257337  B -2.380117   5   1  0.0   3   9  10  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>v3</th>\n      <th>v4</th>\n      <th>v5</th>\n      <th>v6</th>\n      <th>v7</th>\n      <th>v8</th>\n      <th>v9</th>\n      <th>r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-5.244266</td>\n      <td>A</td>\n      <td>-2.544469</td>\n      <td>-12</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-7</td>\n      <td>-19</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.000000</td>\n      <td>A</td>\n      <td>4.922793</td>\n      <td>4</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>11</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-7.882469</td>\n      <td>B</td>\n      <td>0.087773</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-11</td>\n      <td>-20</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-7.155857</td>\n      <td>A</td>\n      <td>-0.713578</td>\n      <td>-13</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>-10</td>\n      <td>-24</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.257337</td>\n      <td>B</td>\n      <td>-2.380117</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>9</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examiner quelles sont les corrélations entre les différentes variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tracer les histogrammes des variables 1, 3, 5. Peut-on soupçonner qu'il y ait des sous ensembles d'exemples avec des comportements différents ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Conversion\n",
    "\n",
    "La variable 2, `v2`, est catégorielle. Convertir cette variable en binaire, sur deux niveaux 0 et 1 ; et mettre à jour le dataframe `df`. Si vous n'arriviez pas à réaliser cette opération, charger le résultat `Data_2023b.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Discrimination (régression logistique)\n",
    "\n",
    "La réponse est la variable `r`. On cherche à prédire cette réponse `r` à partir des variables explicatives `v1` à `v9`. Si le dataframe contient des variables supplémentaires, vous ne les utiliserez pas pour la discrimination. \n",
    "\n",
    "- Séparer les données en une base d'apprentissage et une base de test, avec un ratio 2/3, 1/3. \n",
    "- Apprendre une régression logistique (classe `LogisticRegression` en python/sklearn, fonction `glm` avec le paramètre `family=binomial` en R ou en Python avec statsmodels)\n",
    "- Calculer les scores sur les bases de test et d'apprentissage. Ces scores sont-ils différents, commenter.\n",
    "- Calculer la matrice de confusion (sur la base de test !). Quel est le taux de faux positifs ? NB - Sous python, vous pouvez utiliser `pd.crosstab` pour calculer cette matrice de confusion\n",
    "- Apprendre la régression sur la base complète et calculer le score par validation croisée. Comparer le score obtenu par validation croisée à celui obtenu sur la base de test. Quel est l'intérêt de la validation croisée (au moins si les données sont en nombre faible) ?\n",
    "\n",
    "\n",
    "NB - la variable `v6` présente des valeurs manquantes NA. **Si** cela posait des difficultés à la méthode que vous employez, ce n'est pas obligé, vous pouvez (i) soit supprimer les lignes correspondantes (ii) soit utiliser le fichier `Data_2023c.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Régression linéaire et de Poisson\n",
    "\n",
    "On est ennuyé avec les valeurs manquantes dans la variable `v6`. On décide d'imputer ces valeurs manquantes. Pour cela, on va tenter de prédire les valeurs manquantes à partir des autres variables. \n",
    "\n",
    "Sous R, vous pourrez utilier la fonction `lm`, et sous Python, vous pourrez charger l'équivalent par `from LinearRegression_in_Python_like_in_R import lm`. Vous pouvez également utiliser un modèle linéaire généralisé `glm` ; sous Python vous pourrez utiliser la fonction `glm` de statsmodels, et les fonctions de résumé et de diagnostique selon `from GLMRegression_in_Python_like_in_R import GLMsummary, glm_residplot`\n",
    "\n",
    "\n",
    "- Suivant les outils que vous utilisez, vous pourrez ou pas utiliser la base `df` avec les valeurs manquantes. Le cas échéant, supprimer toutes les lignes sans NA pour la variable `v6`. Sous Python, vous pourrez utiliser `.dropna`, mais également`.notna()` pour accéder aux indices des lignes ne contenant pas de NA, et `.isna()` pour les lignes avec NA. \n",
    "\n",
    "**4.1 - Régression linéaire**\n",
    "- Effectuer une prédiction lineaire de `v6` en fonction des autres variables explicatives (les variables en `v.`, pas `r`)\n",
    "- Calculer l'erreur quadratique moyenne entre les valeurs exactes et prédites de `v6`. Vous pouvez éventuellement directement accéder à un prédicteur via une méthode `.predict()`, voire même directement aux residus via un attribut `.residuals` \n",
    "- Au vu des résultats, quelles sont les variables importantes\n",
    "- Examiner les graphes de diagnostic. Pouvez vous soupçonner une non linarité, pourquoi ? \n",
    "- Effectuer une nouvelle prédiction en ajoutant la variable `v3**2`. Que devient alors l'erreur quadratique moyenne ? La variable v5 est-elle utile ? \n",
    "- Si vous ajoutiez `v5**2` plutôt que `v3**2`, quelle seraient l'erreur quadratique moyenne ? Commentaires. \n",
    "\n",
    "**4.2 - Régression de Poisson**\n",
    "- Effectuer une régression de Poisson de `v6` en fonction des autres variables explicatives (les variables en `v.`, pas `r`)\n",
    "- Reprendre toutes les autres questions précémment traitées avec la régression linéaire (performances, variables à retenir, graphes de diagnostic, non-linéarité...)\n",
    "- Comparer les résulats obtenus par les deux approches et commenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 - Imputation**\n",
    "- Rempacer les données manquantes dans `df` en prédisant les valeurs manquantes à l'aide du modèle linéaire. \n",
    "Si vous ne voyez pas comment faire, utiliser `Data_2023c.csv` dans la suite. \n",
    "- Enfin, calculez une régression logistique pour prédire la variable $r$ et évaluez les performances (sur une base de test ou par validation croisée, comme en 3). Comparez le score au score obtenu précédentemment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Comme vous l'avez peut-être observé, on soupçonne que les données puissent être en fait composées de différents *clusters*, qui possèderaient des caractéristiques différentes. L'idées est alors qu'on pourrait -- peut-être, améliorer les performances de discrimination et utilisant des modèles différents sur chacun des clusters. \n",
    "\n",
    "Au vu des histogrammes, on teste l'hypothèse de 3 clusters. \n",
    "\n",
    "- Utiliser la méthode kmeans pour définir 3 clusters. Tracer les histogrammes de répartition des labels identifiés par kmeans. \n",
    "- Ajouter au dataframe une colonne 'km_labels' contenant le label du cluster pour chaque exemple. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NB - Sous Python \n",
    "```\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Séparer votre dataframe en une base d'apprentissage `train` (les 3000 premières lignes) et une base de test `test` (les 1500 suivantes). \n",
    "- Pour chacun des groupes (vous pouvez filtrer vos données sur la valeur de la colonne 'km_labels')\n",
    "   - calculer un modèle de régression logistique \n",
    "   - et les performances correspondantes (score $s_i$, taux de faux positifs $t_i$) sur la base de test, pour les exemples du même groupe\n",
    "   - si $n_1$, $n_2$, $n_3$ sont les nombres d'exemples dans chacun des groupes, $s_1$, $s_2$, $s_3$ les scores dans chaque groupe, alors le score global sera \n",
    "$$\n",
    "   s = \\frac{n_1s_1  + n_2s_2 + n_3s_3} {n_1  + n_2 + n_3}\n",
    "$$\n",
    "   et pour le taux de faux positifs,\n",
    "$$\n",
    "   t = \\frac{n_1t_1  + n_2t_2 + n_3t_3} {n_1  + n_2 + n_3}\n",
    "$$\n",
    "- Comparez les performances aux performances obtenues précédemment et commentez   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation de la stabilité par bootstrap\n",
    "\n",
    "- Ré-échantillonnez l'ensemble `train` et générez le même nombre d'échantillons, puis apprenez vos modèles et calculez le score global comme précédemment sur la base de test _inchangée_. \n",
    "- Effectuez ceci disons B=200 fois, en stockant les valeurs de scores et taux de faux positifs. \n",
    "- Tracez les histogrammes des valeurs obtenues\n",
    "- Donnez les moyennes et intervalles de confiance correspondant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "latex_bib.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "ctrl-e",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "pyVarInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
