{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à la régression linéaire\n",
    "Jean-François Bercher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-20T09:06:58.530919900Z",
     "start_time": "2023-11-20T09:06:58.522983800Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display, HTML, Image, Javascript\n",
    "from ipywidgets import interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pour tracés en 3d\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-20T09:07:01.177626800Z",
     "start_time": "2023-11-20T09:07:00.723465100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Configuring matplotlib formats\n",
      "... Configuring matplotlib with inline figures\n",
      "... Importing numpy as np, scipy as sp, pyplot as plt, scipy.stats as stats\n",
      "   ... scipy.signal as sig\n",
      "... Importing widgets, display, HTML, Image, Javascript\n",
      "... Some LaTeX definitions\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n$$\\require{color}\n\\require{cancel}\n\\def\\tf#1{{\\mathrm{FT}\\left\\{ #1 \\right\\}}}\n\\def\\flecheTF{\\rightleftharpoons }\n\\def\\TFI#1#2#3{{\\displaystyle{\\int_{-\\infty}^{+\\infty} #1 ~e^{j2\\pi #2 #3} \n~\\dr{#2}}}}\n\\def\\TF#1#2#3{{\\displaystyle{\\int_{-\\infty}^{+\\infty} #1 ~e^{-j2\\pi #3 #2} \n~\\dr{#2}}}}\n\\def\\sha{ш}\n\\def\\dr#1{\\mathrm{d}#1}\n\\def\\egalpardef{\\mathop{=}\\limits^\\triangle}\n\\def\\sinc#1{{\\mathrm{sinc}\\left( #1 \\right)}}\n\\def\\rect{\\mathrm{rect}}\n\\definecolor{lightred}{rgb}{1,0.1,0}\n\\def\\myblueeqbox#1{{\\fcolorbox{blue}{lightblue}{$\textcolor{blue}{ #1}$}}}\n\\def\\myeqbox#1#2{{\\fcolorbox{#1}{light#1}{$\textcolor{#1}{ #2}$}}}\n\\def\\eqbox#1#2#3#4{{\\fcolorbox{#1}{#2}{$\\textcolor{#3}{ #4}$}}}\n% border|background|text\n\\def\\eqboxa#1{{\\boxed{#1}}}\n\\def\\eqboxb#1{{\\eqbox{green}{white}{green}{#1}}}\n\\def\\eqboxc#1{{\\eqbox{blue}{white}{blue}{#1}}}\n\\def\\eqboxd#1{{\\eqbox{blue}{lightblue}{blue}{#1}}}\n\\def\\E#1{\\mathbb{E}\\left[#1\\right]}\n\\def\\ta#1{\\left<#1\\right>}\n\\def\\egalparerg{{\\mathop{=}\\limits_\\mathrm{erg}}}\n\\def\\expo#1{\\exp\\left(#1\\right)}\n\\def\\d#1{\\mathrm{d}#1}\n\\def\\wb{\\mathbf{w}} \n\\def\\sb{\\mathbf{s}} \n\\def\\xb{\\mathbf{x}}\n\\def\\Rb{\\mathbf{R}} \n\\def\\rb{\\mathbf{r}} \n\\def\\mystar{{*}}\n\\def\\ub{\\mathbf{u}}\n\\def\\wbopt{\\mathop{\\mathbf{w}}\\limits^\\triangle}\n\\def\\deriv#1#2{\\frac{\\mathrm{d}#1}{\\mathrm{d}#2}}\n\\def\\Ub{\\mathbf{U}}\n\\def\\db{\\mathbf{d}}\n\\def\\eb{\\mathbf{e}}\n\\def\\vb{\\mathbf{v}}\n\\def\\Ib{\\mathbf{I}}\n\\def\\Vb{\\mathbf{V}}\n\\def\\Lambdab{\\mathbf{\\Lambda}}\n\\def\\Ab{\\mathbf{A}}\n\\def\\Bb{\\mathbf{B}}\n\\def\\Cb{\\mathbf{C}}\n\\def\\Db{\\mathbf{D}}\n\\def\\Kb{\\mathbf{K}}\n\\def\\sinc#1{\\mathrm{sinc\\left(#1\\right)}}\n$$\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Defining figures captions \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n.caption {\nfont-weight: normal;\ntext-align: left;\nwidth:60%; margin-left:10%; border:2px solid; padding-top:5px; padding-bottom:5px;\nbackground-color:white;border-color:#efd3d7;color:black;\nborder-radius:8px;-webkit-border-radius:8px;-moz-border-radius:8px;border-radius:8px\n}\n</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Loading customized Javascript for interactive solutions (show/hide)\n"
     ]
    }
   ],
   "source": [
    "%run nbinit.ipy\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-20T09:07:02.965770100Z",
     "start_time": "2023-11-20T09:07:02.880747800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\nem {\n    color: green;\n}\nstrong\n{\n    color: blue;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "em {\n",
    "    color: green;\n",
    "}\n",
    "strong\n",
    "{\n",
    "    color: blue;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-20T09:07:03.970054200Z",
     "start_time": "2023-11-20T09:07:03.907920400Z"
    }
   },
   "outputs": [],
   "source": [
    "# redéfinit interactive de manière à pouvoir passer des arguments\n",
    "# et récupérer les résultats \n",
    "def interactive(f,*args,**kwargs):\n",
    "    import ipywidgets\n",
    "    def fn(*args,**kwargs):\n",
    "        f(*args,**kwargs)\n",
    "    w=ipywidgets.interactive(fn,*args,**kwargs)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-20T09:07:06.770164400Z",
     "start_time": "2023-11-20T09:07:05.100337400Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rpy2'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mload_ext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrpy2.ipython\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2432\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2430\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2431\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2432\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2434\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2435\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2436\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2437\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001B[0m, in \u001B[0;36mExtensionMagics.load_ext\u001B[1;34m(self, module_str)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m module_str:\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m UsageError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing module name.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 33\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextension_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124malready loaded\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m extension is already loaded. To reload it, use:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m module_str)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\extensions.py:76\u001B[0m, in \u001B[0;36mExtensionManager.load_extension\u001B[1;34m(self, module_str)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;124;03mfunction, or None if it succeeded.\u001B[39;00m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module_str \u001B[38;5;129;01min\u001B[39;00m BUILTINS_EXTS:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\extensions.py:91\u001B[0m, in \u001B[0;36mExtensionManager._load_extension\u001B[1;34m(self, module_str)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshell\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module_str \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mmodules:\n\u001B[1;32m---> 91\u001B[0m         mod \u001B[38;5;241m=\u001B[39m \u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m     mod \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules[module_str]\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_load_ipython_extension(mod):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1204\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1126\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1204\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1140\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'rpy2'"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression / Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La régression linéaire est un modèle très simple, *souvent inexact*, mais extrêmement efficace. En outre, les éléments que nous allons présenter ici seront réutilisés tout au long du cours, qui bâtira à la fois sur les concepts et les outils. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous un exemple de fonction linéaire avec un bruit additif. Le premier problème sera de retrouver, *au mieux*, les paramètres de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.222536800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o y\n",
    "L=100\n",
    "y =  rnorm(L)+ 0.02*seq(1,L)\n",
    "plot(y, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - The *Advertising data* \n",
    "\n",
    "Ces données sont utilisées dans notre livre de référence [An Introduction to Statistical Learning\n",
    "with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/). Elles consistent en les nombre de  ventes d'un certain produit sur 200 marchés (villes) différent(e)s, ainsi la répartition du budget publicitaire sur chacun de ces marchés pour trois médias différents : publicité à la télévision, à la radio et dans les journaux. Bien sûr il manque Internet...\n",
    "\n",
    "Étant donné un certain budget publicitaire, une première interrogation est de savoir si la publicité sert à quelque chose, et dans l'affermative, la question est donc de savoir comment répartir au mieux ce budget entre les trois médias afin de maximiser le nombre de ventes.. \n",
    "\n",
    "On doit donc s'atteler à bâtir un modèle qui puisse permettre de *prédire les ventes* en fonction de la part de budget allouée aux trois médias. \n",
    "\n",
    "Les portions de code ci-dessous indiquent comment récupérer ces données et présentent deux figures : d'une part les ventes brutes en fonction de leur index naturel, puis les ventes en fonction du budget publicitaire alloué à la TV. Il semble manifestement qu'il y ait un lien entre ce budget et le nombre de ventes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.226214300Z"
    }
   },
   "outputs": [],
   "source": [
    "##%%R -o advertising\n",
    "#advertising=read.csv(file = \"http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv\")\n",
    "#summary(advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.231598900Z"
    }
   },
   "outputs": [],
   "source": [
    "##%%R \n",
    "#write.csv(advertising, file = \"Advertising.csv\", row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture avec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.236825300Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o advertising\n",
    "advertising = read.csv(file = \"Advertising.csv\")\n",
    "plot(advertising$Sales)\n",
    "plot(advertising$Sales~advertising$TV)\n",
    "#$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ajustement d'une droite de régression à un nuage de points. \n",
    "\n",
    "On suppose que la relation entre la variable *dépendante* $Y$ et la variable *indépendante* $X_1$ (dite aussi *explicative* ou encore *prédicteur*) est une dépendance **linéaire**. Typiquement, on aurait un modèle de la forme\n",
    "\\begin{equation}\n",
    "\\eqboxd{\n",
    "\\displaystyle{\n",
    "Y = \\beta_0 + \\beta_1 X_1+\\epsilon,\n",
    "}}\n",
    "\\end{equation}\n",
    "où les $\\beta_i$ sont les coefficients du modèle : $\\beta_0$ est l'*intercept* et $\\beta_1$ la pente --*slope*, dans le cas d'un modèle avec une seule variable indépendante $X_1$ ; $\\epsilon$ comprend à la fois une erreur *irréductible* et une *erreur de modèle*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.243833700Z"
    }
   },
   "outputs": [],
   "source": [
    "# version Python\n",
    "%matplotlib inline\n",
    "\n",
    "def plt_line(x, y, a, b, vert_bars):\n",
    "    if isinstance(x,(ndarray,list)):  x=pd.Series(x)\n",
    "    if isinstance(x,(ndarray,list)):  y=pd.Series(y)        \n",
    "    plt.plot(x,y,'o', color=\"red\")\n",
    "    plt.plot(x,a*x+b, color=\"blue\")\n",
    "    plt.ylim([0, 30])\n",
    "    plt.ylabel(\"Nombre de ventes\")\n",
    "    plt.xlabel(\"Budget publicitaire (TV)\")\n",
    "    if vert_bars:\n",
    "        for k in x.index:\n",
    "            plt.plot([x[k], x[k]], [a*x[k]+b, y[k]],color=\"red\")\n",
    "    plt.text(1.1*x.max(), 0.9*y.max(), \"SSE: {:3.3f}\".format(np.sum((y-a*x-b)**2)), fontsize=16, \n",
    "             bbox=dict(facecolor='red', boxstyle=\"round,pad=0.6\", edgecolor='red', alpha=0.5))\n",
    "    # plt.show() # for use with interact --> https://github.com/ipython/ipython/issues/10376\n",
    "    #print(vert_bars)\n",
    "    \n",
    "def wplt_line(val):\n",
    "    a=b1_choice.value;\n",
    "    b=b0_choice.value;\n",
    "    vert_bars=bar.value;\n",
    "    clear_output(wait=True)\n",
    "    plt_line(x, y, a, b, vert_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.247582200Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Layout\n",
    "x=advertising['TV']\n",
    "y=advertising['Sales']\n",
    "\n",
    "b0_choice=widgets.FloatSlider(description=\"Choix de l'intercept\",min=0, max=10, step=0.2, value=4.8, readout_format='.3f')\n",
    "b1_choice=widgets.FloatSlider(description=\"Choix de la pente (slope)\",min=-0.1, max=0.2, step=0.005, value=0.045, readout_format='.3f')\n",
    "bar=widgets.Checkbox(value=False, description=\"Barres verticales\")\n",
    "b0_choice.layout = Layout(width='90%')\n",
    "b1_choice.layout = Layout(width='90%')\n",
    "\n",
    "b0_choice.observe(wplt_line,names=\"value\")\n",
    "b1_choice.observe(wplt_line,names=\"value\")\n",
    "bar.observe(wplt_line,names=\"value\")\n",
    "\n",
    "#c=widgets.HBox(children=[fcw,Lw])\n",
    "#d=widgets.VBox(children=[c,imprespw])\n",
    "d=widgets.VBox(children=[b0_choice,b1_choice,bar])\n",
    "d.box_style=\"info\"\n",
    "d.layout = Layout(width='60%', align_items='baseline', border_radius=5)\n",
    "#display(d)\n",
    "\n",
    "_=interact(plt_line,x=fixed(x), y=fixed(y), a=b1_choice, b=b0_choice, vert_bars=bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def\\betab{\\boldsymbol{\\beta}}$\n",
    "### Calcul des coefficients --  cas d'un seul prédicteur \n",
    "\n",
    "Un critère raisonnable pour estimer les paramètres du modèle est le critère des moindres carrés : il s'agit simplement de minimiser la somme des carrés des résidus (*residual sum of squares*) : \n",
    "\n",
    "\\begin{align}\n",
    "RSS(\\betab) & = \\sum_{i=1}^N  \\left(y_i - \\hat{y}_i\\right)^2 \\\\ \n",
    "&=  \\sum_{i=1}^N  \\left(y_i- \\beta_0 - \\beta_1 x_{i1} \\right)^2,\n",
    "\\end{align}\n",
    "\n",
    "où $x_{i1}$ désigne les différentes observations de $X_1$. \n",
    "\n",
    "La technique de régression linéaire basée sur ces moindres carrés est souvent dénommée OLS pour *Ordinary Least Squares* dans la littérature.\n",
    "\n",
    "\n",
    "Avec un seul prédicteur $X_1$, on peut dériver directement le critère (*cost function*) par rapport à $\\beta_0$ et $\\beta_1$ pour obtenir\n",
    "$$\n",
    "\\beta_0 = \\frac{1}{N}\\sum_{i=1}^{N}y_i - \\beta_1 \\frac{1}{N}\\sum_{i=1}^{N}x_i\n",
    "= \\overline{y}-\\beta_1\\overline{x}.\n",
    "$$ \n",
    "\n",
    "Cette valeur dépend de $\\beta_1$ qui n'est pas encore déterminé et nous pouvons maintenant écrire le critère en fonction seulement de $\\beta_1$ : \n",
    "$$\n",
    "RSS=\\sum_{i=1}^{N} (y_i -\\bar{y} - \\beta_1 (x_i-\\bar{x}))^2\n",
    "$$\n",
    "ce qui entraîne pour $\\beta_1$ : \n",
    "$$ \n",
    "\\eqboxa{\n",
    "\\beta_1=\\frac{\\sum_{i=1}^{N} (y_i -\\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^{N} (x_i-\\bar{x})^{2}}.\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarque\n",
    "Ce coefficient dépend donc du rapport de l'estimée de la covariance entre X et Y à l'estimée de la variance de X :  \n",
    "$$\n",
    "\\beta_1=\\hat{cov}(X,Y)/\\hat{\\sigma}_X^2, \n",
    "$$\n",
    "c'est-à-dire, à un facteur près, du coefficient de corrélation entre $X$ et $Y$. **Il est ainsi instructif de constater que le coefficient de prédiction est directement lié au coefficient de corrélation entre les variables dépendante et explicative.** \n",
    "Attention au fait que cela sera moins clair (et donc moins intuitif) dans le cas d'une prédiction multivariée du fait des corrélations potentielles \n",
    "*entre* les prédicteurs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration en R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.252771700Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "?lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.259025900Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o advertising\n",
    "advertising = read.csv(file = \"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.263188400Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o lmModel\n",
    "lmModel = lm(Sales ~ TV, data=advertising)\n",
    "print(lmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.267422900Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(advertising$Sales~advertising$TV)\n",
    "abline(lmModel,col=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.274704700Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et en fonction de la Radio ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.278162Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "lmModel = lm(Sales ~ Radio, data=advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.286109600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "lmModel = lm(Sales ~ Newspaper, data=advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire -- Cas multivarié \n",
    "\n",
    "Utiliser une seule variable explicative peut être restrictif. Bien entendu, la variable *dépendante* $Y$  peut s'expliquer en fonction de plusieurs  variables *indépendantes* $X_1, \\ldots, X_p$. On suppose à nouveau que la relation est une  dépendance **linéaire**. Le modèle prend alors la forme\n",
    "$$\n",
    "\\eqboxd{\n",
    "\\displaystyle{\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\ldots \\beta_p X_p + \\epsilon,\n",
    "}}\n",
    "$$\n",
    "où les $\\beta_i$ sont les coefficients du modèle. Les variables indépendantes $X_i$ sont aussi appelées variables *explicatives* ou encore *prédicteurs*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Typiquement, on dispose de données d'*apprentissage* à partir desquelles on peut estimer les  coefficients $\\beta_j$ du modèle (il s'agit donc là véritablement d'une technique *supervisée*). \n",
    "\n",
    "Étant donné ces *estimées* des coefficients, il est possible de *prédire* les valeurs futures par \n",
    "$$\n",
    "\\hat{y} =\\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\ldots \\hat{\\beta}_p x_p. \n",
    "$$\n",
    "$\\hat{y}$ indique une prédiction faite à partir des variables $X = x$.\n",
    "Le symbole $\\hat{}$ dénote une valeur estimée. On pourra également évaluer la qualité du modèle en testant les performances sur une *base de test*. On appelle *résidu* la différence entre la valeur exacte et la valeur prédite :  $y_i - \\hat{y}_i$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  $\\def\\betab{\\mathbf{\\beta}}$\n",
    "Un critère raisonnable pour estimer les paramètres du modèle est le critère des moindres carrés : il s'agit simplement de minimiser la somme des carrés des résidus (*residual sum of squares*) : \n",
    "\\begin{align}\n",
    "RSS(\\betab) & = \\sum_{i=1}^N  \\left(y_i - \\hat{y}_i\\right)^2 \\\\ \n",
    "&=  \\sum_{i=1}^N  \\left(y_i- \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2.\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\def\\yb{\\mathbf{y}}\\def\\Xb{\\mathbf{X}}$\n",
    "Ce critère peut se mettre sous la forme matricielle \n",
    "$$\n",
    "RSS(\\betab) = \\left( \\yb - \\Xb\\betab\\right)^T\\left( \\yb - \\Xb\\betab\\right),\n",
    "$$\n",
    "où $\\yb$ est un vecteur colonne de dimension $N$ et $\\Xb$ une matrice de dimension $N\\times(p+1)$ (la première colonne de $\\Xb$ est composée de 1 de manière à prendre en compte le terme $\\beta_0$ \\footnote{Dans certaines fonctions de scikit-learn, cette colonne de 1 peut-être intégrée ou non}. Ce critère est une forme quadratique en les $(p+1)$ paramètres inconnus. Lorsque $\\Xb$ est de rang colonne plein, on a une solution unique, qui peut être obtenue en annulant le gradient\n",
    "$$\n",
    "\\frac{\\partial RSS(\\betab)}{\\partial \\betab} = -2 \\Xb^T \\left( \\yb - \\Xb\\betab\\right). \n",
    "$$\n",
    "Ceci conduit donc à la solution\n",
    "$$\n",
    "\\Xb^T \\left( \\yb - \\Xb\\betab\\right) = \\mathbf{0} \\Rightarrow  \\Xb^T \\yb = \\Xb^T\\Xb\\betab,\n",
    "$$\n",
    "soit \n",
    "\\begin{equation} \\label{eq:beta_estimates}\n",
    "\\eqboxd{\n",
    "\\hat{\\betab} = \\left(\\Xb^T\\Xb\\right)^{-1} \\Xb^T \\yb\n",
    "}\n",
    "\\end{equation}\n",
    "On peut alors prédire $\\yb$ par\n",
    "$$\n",
    "\\label{eq:ypred}\n",
    "\\hat{\\yb} = \\Xb\\hat{\\betab} =  \\Xb \\left(\\Xb^T\\Xb\\right)^{-1} \\Xb^T \\yb\n",
    "$$\n",
    "La matrice \n",
    "\\begin{equation}\n",
    "\\label{eq:hatmatrix}\n",
    "\\eqboxb{\n",
    "H = \\Xb \\left(\\Xb^T\\Xb\\right)^{-1} \\Xb^T }\n",
    "\\end{equation}\n",
    "\n",
    "est parfois appelée la *hat matrix* dans la mesure où elle met un chapeau *hat* sur $\\yb$. Vous pourrez consulter une note pas trop récente sur les moindres carrés en suivant [ce lien](Note_rapide_moindres_carrés.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rang de $X^TX$, cas singulier, corrélation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application au cas des données de publicité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et c'est là que cela devient sympathique avec R : il suffit d'utiliser la fonction `lm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lm` accepte un langage de formule pour spécifier le modèle à effectuer. On en trouvera une description dans cette [référence][1]. \n",
    "\n",
    "[1]: http://faculty.chicagobooth.edu/richard.hahn/teaching/FormulaNotation.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.291510600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "lmModel = lm('Sales ~ Newspaper', advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La signification des coefficients est la suivante : à budget Radio fixé, l'augmentation des ventes est de ~46 unités par tranches de 1000 dollars d'investissement TV. Il semble que le budget Radio ait plus d'effet sur les ventes, mais les sommes en jeu sont plus faibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.297673600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "print(names(lmModel))\n",
    "confint(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dès lors, il est possible de *prédire* les ventes pour une répartition données du budget publicitaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.302652400Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o coeffs\n",
    "#\n",
    "lmModel = lm(Sales ~ Radio+TV, data=advertising)\n",
    "coeffs=lmModel$coefficients\n",
    "lmModel\n",
    "#$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.312176700Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "predict(lmModel,data.frame(TV=250, Radio=50),interval=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.316834800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "predict(lmModel,data.frame(TV=c(50,150,250), Radio=c(50,150,250)),interval=\"confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous une illustration de la surface de prédiction en fonction des deux variables, et des erreurs de prédiction associées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.323439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a coordinate grid\n",
    "Radio = np.arange(0,50)\n",
    "TV = np.arange(0,300)\n",
    "\n",
    "B1, B2 = np.meshgrid(Radio, TV, indexing='xy')\n",
    "Z = np.zeros((TV.size, Radio.size))\n",
    "\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "        Z[i,j] =(coeffs[0] + B1[i,j]*coeffs[1] + B2[i,j]*coeffs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.330629600Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plot\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('Regression: Sales ~ Radio + TV Advertising', fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = advertising.Radio\n",
    "y = advertising.TV\n",
    "z = advertising.Sales\n",
    "\n",
    "ax.scatter(x, y, z, c='r', marker='o')\n",
    "ax.plot_surface(B1, B2, Z, rstride=10, cstride=5, alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('Radio')\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylabel('TV')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_zlabel('Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.334470100Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"%matplotlib inline\n",
    "# Create plot\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('Regression: Sales ~ Radio + TV Advertising', fontsize=20)\n",
    "\n",
    "ax = axes3d.Axes3D(fig)\n",
    "\n",
    "ax.plot_surface(B1, B2, Z, rstride=10, cstride=5, alpha=0.4)\n",
    "ax.scatter3D(advertising.Radio, advertising.TV, advertising.Sales, c='r')\n",
    "\n",
    "#for k in x:\n",
    "#     plt.plot([k, k], [a*k, y[k]],color=\"red\")\n",
    "\n",
    "ax.set_xlabel('Radio')\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylabel('TV')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_zlabel('Sales')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.342158700Z"
    }
   },
   "outputs": [],
   "source": [
    "azim=widgets.FloatSlider(min=-180, max=180, step=1, value=-60)    \n",
    "elev=widgets.FloatSlider(min=-180, max=360, step=1, value=30)   \n",
    "\n",
    "#ax.set_axis_off()\n",
    "@interact(elev=elev, azim=azim)\n",
    "def view(elev, azim):\n",
    "    ax.view_init(elev, azim)\n",
    "    #ax.azim=azim\n",
    "    #ax.elev=elev\n",
    "    display(ax.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation des performances   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque l'on effectue une régression linéaire multiple, on doit s'intéresser aux questions suivantes : \n",
    "\n",
    "1. La régression est-elle utile ? En d'autres termes, au moins un des prédicteurs permet-il d'expliquer les données ?\n",
    "2. Quels sont les prédicteurs utiles ? Lesquels peut-on rejeter ?\n",
    "3. Quelle est la qualité de la régression ? \n",
    "4. Comment peut-on prédire de nouvelles données et quelle est la qualité de la prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de covariance\n",
    "\n",
    "$\\def\\Var#1{\\mathrm{Var}\\left\\{#1\\right\\}}$\n",
    "Il est aisé de calculer la matrice de covariance de $\\hat\\betab$ directement à partir de (\\ref{eq:beta_estimates}) : \n",
    "$$\n",
    "\\Var{\\hat\\betab} = \\E{\\hat\\betab\\hat\\betab^T} = \\left(\\Xb^T\\Xb\\right)^{-1} \\sigma^2\n",
    "$$\n",
    "(pour alléger l'écriture on a supposé que $\\yb$ est centré, et donc $\\hat\\betab$ également). On peut également estimer la variance du bruit par \n",
    "$$\n",
    "\\hat{\\sigma^2} = \\frac{1}{N-p-1} \\sum_{i=1}^N (y_i - \\hat{y}_i )^2,\n",
    "$$\n",
    "où le $N-p-1$ correspond au nombre de degrés de liberté effectif de la variable $y_i - \\hat{y}_i$, et rend l'estimateur non biaisé.  \n",
    "Lorsque l'erreur de modèle $\\epsilon$ peut-être considérée comme gaussienne centrée, $\\epsilon \\sim N(0,\\sigma^2)$, alors $\\hat\\betab$ est gaussien vectoriel $\\hat\\betab \\sim N\\left(\\mathbf{0}, \\left(\\Xb^T\\Xb\\right)^{-1} \\sigma^2\\right)$. L'estimée de la variance, à un facteur près, est une variable du chi2 à $(N-p-1)$ degrés de liberté. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSE, R2\n",
    "\n",
    "*  **Le RSE** : Le RSS est difficile à appréhender. On lui préfère souvent **le RSE**, *residual standard error*, qui est simplement la racine carrée de la variance estimée :\n",
    "\n",
    "$$\n",
    "RSE  =\\sqrt{\\hat{\\sigma^2}} = \\sqrt{\\frac{RSS}{N-p-1} }.\n",
    "$$\n",
    "\n",
    "On pourra comprendre le RSE comme une mesure d'erreur de modèle, où d'insuffisance du modèle. \n",
    "\n",
    "* **Le $R^2$** : Le RSE est mesuré sur la même échelle que $Y$ (donc sensible à l'échelle de travail -- ne permet pas de comparer des modèles entre eux), et ne mesure pas le gain apporté par la modélisation. L'idée est donc de se donner une référence comme étant l'erreur en l'absence de modélisation et de normaliser les choses vis-à-vis de cette référence. \n",
    "En l'absence de variable explicative, le modèle ne comprend donc que $\\beta_0$. Vous montrerez facilement que dans ce cas on obtient $\\beta_0 = \\bar{y}={1}/{N}\\sum_{i=1}^{N}y_i$. On appelle **TSS** la somme des carrés des erreurs correspondantes (c'est-à-dire le RSS correspondant)\n",
    "\n",
    "$$\n",
    "TSS = \\sum_{i=1}^N  \\left(y_i - \\bar{y} \\right)^2. \n",
    "$$\n",
    "Bien entendu le RSS pour un modèle plus complet -- par exemple avec un prédicteur, est nécessairement plus faible car on cherche alors à minimiser $\\sum_{i=1}^N  \\left(y_i - \\beta_0 - \\beta_1 x_{i1} \\right)^2$ et on obtiendra le TSS dans le \"pire cas\" où $\\beta_1=0$. En peut montrer que l'on a exactement (c'est un théorème de Pythagore)\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N  \\left({y}_i - \\bar{y} \\right)^2  = \\sum_{i=1}^N  \\left({y}_i - \\hat{y}_i \\right)^2  + \\sum_{i=1}^N  \\left(\\hat{y}_i - \\bar{y} \\right)^2, \n",
    "$$\n",
    "soit\n",
    "\n",
    "$$\n",
    "\\eqboxc{\n",
    "TSS = RSS + ESS\n",
    "}\n",
    "$$\n",
    "où ESS vaut pour *Explained Sum of Squares* et représente la part de la variance globale qui est expliquée par le modèle. Il ne reste plus qu'à normaliser, et on pose alors\n",
    "\n",
    "$$\n",
    "\\eqboxd{\n",
    "R^2 = \\frac{ESS}{TSS} = 1 - \\frac{RSS}{TSS}\n",
    "}\n",
    "$$\n",
    "qui représente la proportion de la variance expliquée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalle de confiance\n",
    "\n",
    "Considérons l'estimée d'un des coefficients $\\beta$, disons $\\hat{\\beta_j}$. Cette estimée est gaussienne, de variance $v_j \\sigma^2$, où $v_j$ désigne le $j^{\\mathrm{e}}$ terme de la diagonale de $\\left(\\Xb^T\\Xb\\right)^{-1}$.  On peut donc construire un intervalle de confiance à $(1-2\\alpha)$ selon\n",
    "$$\n",
    "\\eqboxc{\n",
    "\\left(\\hat{\\beta_j} - z^{(1-\\alpha)} \\sqrt{v_j} \\sigma, \\hat{\\beta_j} + z^{(1-\\alpha)} \\sqrt{v_j} \\sigma\\right)\n",
    "}\n",
    "$$\n",
    "où $z^{(1-\\alpha)}$ est le $(1-\\alpha)$ quantile d'une gaussienne normalisée. Typiquement, pour $\\alpha=0.025$, on a $z^{(1-\\alpha)}=1.96$, pour $\\alpha=0.05$, on a $z^{(1-\\alpha)}=1.645$. Pour un intervalle de confiance à 95%, on a donc approximativement 95% de chance que l'intervalle \n",
    "$$\n",
    "\\eqboxc{\n",
    "\\left(\\hat{\\beta_j} - 2 \\sqrt{v_j} \\sigma, \\hat{\\beta_j} + 2\\sqrt{v_j} \\sigma\\right)\n",
    "}\n",
    "$$\n",
    "contienne la vraie valeur $\\beta_j$. Attention au fait que l'intervalle de confiance présenté ci-dessus en imaginant que l'on connait $\\sigma^2$, ce qui n'est pas le cas. En réalité, on remplace $\\sigma^2$ par son estimée et il faudrait rechercher les quantiles d'une variable de student plutôt que d'une gaussienne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test d'hypothèses, p-value \n",
    "\n",
    "La théorie des tests permet de tester ici si un coefficient de prédiction $\\beta_j$ existe ou non. On considère classiquement les deux hypothèses \n",
    "\n",
    "- $H_0$ : $\\beta_j=0$ (« pas de relation entre $Y$ et $X_j$ »)\n",
    "- $H_1$ : $\\beta_j\\neq 0$\n",
    "\n",
    "Pour cela, on compare la valeur estimée à son écart-type (lui aussi estimé). Grossièrement, si $\\beta_j$ est de l'ordre de grandeur ou plus grand que l'écart-type, on aura tendance à rejeter l'hypothèse selon laquelle $\\beta_j=0$. Lorsque $\\beta_j$ est inférieur à son écart-type, on ne pourra pas rejeter la possibilité $\\beta_j=0$.\n",
    "\n",
    "On définit un score normalisé par \n",
    "$$\n",
    "t_j = \\frac{\\hat{\\beta_j}}{\\sqrt{v_j} \\hat{\\sigma}}. \n",
    "$$\n",
    "Sous l'hypothèse $H_0$, c'est-à-dire si le véritable $\\beta_j$ est nul, alors $\\hat{\\beta_j}$ et $\\hat{\\sigma}$ étant respectivement gaussien et du chi-2 à $(N−p−1)$ degrés de liberté, leur rapport est une [variable de Student](https://fr.wikipedia.org/wiki/Loi_de_Student) à $(N−p−1)$ degrés de liberté. La probabilité qu'une telle variable soit égale ou supérieure à la valeur calculée $|t_j|$  est appelée la *p-value* :\n",
    "$$\n",
    "p_j = \\mathrm{Pr}\\left(X \\geq |t_j| \\right).\n",
    "$$\n",
    "Cette *p-value* peut être lue dans une table ou calculée. Elle s'interprète de la manière suivante : \n",
    "\n",
    "- *une faible valeur* indique qu'il est très peu probable d'observer la valeur courante ou supérieure sous $H_0$. En d'autres termes on peut rejeter $H_0$ et inférer que $\\beta_j$ est effectivement non-nul.\n",
    "- *une forte valeur* indique que la probabilité d'obtenir cette valeur sous l'hypothèse nulle est importante et qu'on ne peut donc pas exclure $\\beta_j=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La F-statistic\n",
    "\n",
    "Celle-ci procède de la même idée : procéder à un test d'hypothèse entre deux situations. Typiquement, on compare un modèle \"0\" avec $p_0+1$ coefficients, à un modèle \"1\" avec $p_1+1$ coefficients, $p_1>p_0$. On note RSS0 et RSS1 les RSS correspondants. On compare ensuite ces deux RSS, normalisés par rapport à RSS1, selon\n",
    "$$\n",
    "F = \\frac{\\left(RSS0-RSS1\\right)/(p_1-p_0)}{RSS1/(N-p_1-1)}\n",
    "$$\n",
    "Sous l'hypothèse de résidus gaussiens et sous l'hypothèse H0 (selon laquelle le modèle avec le moins de coefficients est correct), $F$ suit une distribution de Fisher de paramètres $p_1-p_0$ et $N-p_1-1$. Il est alors possible de calculer cette statistique (plus $F$ est élevé et plus on va avoir tendance à rejeter H0 et accepter que le modèle à $p_1$ coefficients apporte quelque chose par rapport à celui à $p_0$ coefficients) ou encore la $p$-value correspondante (plus $p$ est faible plus on peut rejeter $H_0$). \n",
    "\n",
    "On utilisera souvent ce test pour *mesurer si la régression linéaire est utile*. On teste donc si par rapport au modèle de base *baseline* (qui ne comprend que le coefficient $\\beta_0$), un moèle à $p$ coefficients permet de baisser sustantiellement le RSS. On a ainsi\n",
    "\n",
    "- $H_0$ : $\\beta_1=\\beta_2=\\ldots=\\beta_p=0$ (« pas de relation entre $Y$ et les $X_j$ »)\n",
    "- $H_1$ : au moins un des $\\beta_j\\neq 0$.\n",
    "\n",
    "La statistique est alors\n",
    "$$\n",
    "F = \\frac{\\left(TSS-RSS\\right)/(p)}{RSS/(N-p-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les données de publicité (advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.354015100Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "# On examine quelles sont les corrélations \n",
    "cor(advertising[2:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.364037200Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "#install.packages(\"corrplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.375008100Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(corrplot)\n",
    "c=cor(advertising[2:5])\n",
    "corrplot(c, method=\"color\",  addCoef.col=\"black\", addCoefasPercent = TRUE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.384437800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o out\n",
    "out=summary(lmModel)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des prédicteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.388755900Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "est = smf.ols('Sales ~ TV ', advertising).fit()\n",
    "print(est.summary().tables[0])\n",
    "print(est.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.397155300Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "est = smf.ols('Sales ~ TV + Radio', advertising).fit()\n",
    "print(est.summary().tables[0])\n",
    "print(est.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En passant de la prédiction TV à TV+Radio, on constate que le R2 augmente, la p-value de la F-statistique diminue (le modèle est significatif). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.397155300Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "est = smf.ols('Sales ~ TV + Radio+Newspaper', advertising).fit()\n",
    "print(est.summary().tables[0])\n",
    "print(est.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, alorsque le coefficient pour *Newspaper* était tout-à-fait significatif pour une régression linéaire simple, dans le modèle multivarié, le coefficient devient très faible et même inférieur à son écart type. Le R2 n'a pas progressé. La p-value correspondante indique que le coefficient obtenu n'est pas significatif... \n",
    "\n",
    "Comment est-ce possible ? Lorsqu'on observe les corrélations, on observe une corrélation de 35% entre Radio et Newspaper. Ainsi, lorsque Radio augmente, Newspaper également. Maintenant, quand on investit sur la Radio, les ventes augmentent. Donc *il semble* que les newspapers aient une influence sur les ventes alors qu'il est possible que ce ne soit qu'une conséquence de la corrélation : augmenter la radio augmente les ventes et le budget en newspaper, mais newspaper n'influe pas sur les ventes... Une illustration du célèbre \n",
    "**Corrélation n'est pas causalité**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.405164200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration de la corrélation entre Journaux et Radio : peut-on prédire l'un en fonction de l'autre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.410874400Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "news_radio = lm('Newspaper ~  Radio', advertising)\n",
    "plot(advertising$Newspaper~advertising$Radio)\n",
    "abline(news_radio,col=\"red\")\n",
    "summary(news_radio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des variables explicatives**\n",
    "\n",
    "Une question importante donc d'examiner quelles sont les variables à prendre en compte; Nous n'allons faire ici qu'effleurer le sujet car un cours ultérieur abordera plus précisément cette question. Pour bien poser les choses, il faut comprendre que plus on ajoute de variables, plus le RSE diminue et plus le R2 augmente. Il ne semble donc pas y avoir de problème, sauf que le modèle des moindres carrés va aller chercher des infos dans les variables même lorsqu'elles sont insensées. Ci-dessous un petit exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.416403200Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "# On ajoute six colonnes de bruit\n",
    "advertising$extra1 = rnorm(200)\n",
    "advertising$extra2 = rnorm(200)\n",
    "advertising$extra3 = rnorm(200)\n",
    "advertising$extra4 = rnorm(200)\n",
    "advertising$extra5 = rnorm(200)\n",
    "advertising$extra6 = rnorm(200)\n",
    "advertising$extra7 = rnorm(200)\n",
    "advertising$extra8 = rnorm(200)\n",
    "advertising$extra9 = rnorm(200)\n",
    "advertising$extra10 = rnorm(200)\n",
    "#\n",
    "a=c('TV','Radio','Newspaper', 'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'extra6', 'extra7', 'extra8', 'extra9', 'extra10')\n",
    "sformula=\"Sales~\"\n",
    "rsq=vector(); arsq=vector(); predmse=vector();\n",
    "ind = sample(seq_len(200), size = 150)\n",
    "train <- advertising[ind, ]\n",
    "test <- advertising[-ind, ]\n",
    "\n",
    "for (k in seq(13)){\n",
    "    sformula=paste(sformula,a[k],sep=\"+\")\n",
    "    formula=as.formula(sformula)\n",
    "    res= lm(formula, data=train)\n",
    "    #names(summary(res))    \n",
    "    rsq[k]=summary(res)$r.squared  # R-squared\n",
    "    arsq[k]=summary(res)$adj.r.squared #Adjusted R-squared\n",
    "    # Prediction on test\n",
    "    yhat = predict(res, newdata=test)\n",
    "    err = yhat-test$Sales\n",
    "    predmse[k] = mean(err**2)\n",
    "    #\n",
    "    print(paste(a[k],\"--\", summary(res)$r.squared, '--', predmse[k]))\n",
    "    }\n",
    "x=seq(13)\n",
    "#plot(rsq, type='b', xlab='', xaxt='n', ylim=c(0.88, 0.91))\n",
    "plot(predmse, type='b', xlab='', xaxt='n', ylim=c(2, 4))\n",
    "axis(1, at=x, labels=a, las=2)\n",
    "#lines(arsq, type='b', ylim=c(0.88, 0.91))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.423494800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "yhat = predict(res, newdata=test)\n",
    "err = yhat-test$Sales\n",
    "mean(err**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est sur les données nouvelles que les choses se gâtent. En effet, si on a surparamétrisé, -- on appelle cela de l'*overfitting*,  les performances de prédiction sur de nouvelles données se dégradent, et il existe quelque part un ordre optimal : ne pas prendre trop de prédicteurs pour rester stable, mais assez pour approcher au mieux la vérité (qui est inconnue !). On voit dès maintenant qu'il sera nécessaire d'évaluer les résultats sur une base de test indépendante des données d'apprentissage. On reverra cela plus longuement ultérieurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir des données d'apprentissage, on peut penser utiliser directement les $p$-values de chacun des coefficients, accepter les variables correspondantes aux p-values faibles. D'abord ces p-values sont dépendantes du contexte, c'est-à-dire  de l'ensemble des variables considérées dans le modèle. Voir la p-value de Newspaper seul, et de Newspaper avec Radio et TV. Ensuite, lorsqu'on a beaucoup de variables, il est très possible d'obtenir des p-values faibles juste par chance (ou par malchance !) alors que les variables considérées ne sont pas explicatives. \n",
    "\n",
    "La F-statistique ne souffre pas de ce défaut car elle prend en compte le nombre total de prédicteurs.  L'idée va alors être de comparer cette F-statistique pour tous les modèles possibles deux à deux. Le souci, c'est que pour $p$ variables, il y a $2^p$ modèles possibles... cela devient donc très rapidement impratiquable. Il existe différentes stratégies qui permettent de réduire le nombre de modèles à considérer, il s'agit de Forward Selection, Backward Selection et Mixed Selection. Partant de ces modèles, différents critères statistiques Cp, AIC, BIC, adjusted R2 peuvent être utilisés, qui combinent généralement le R2 avec un pénalisation de la dimension du modèle. On pourra également utiliser une stucture de *validation croisée*. À suivre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effets de synergie - Prise en compte de non-linéarités\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synergies\n",
    "\n",
    "Revenons à la représentation du plan de prédiction pour les deux variables explicatives TV et Radio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.428650600Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plot\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('Regression: Sales ~ Radio + TV Advertising', fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = advertising.Radio\n",
    "y = advertising.TV\n",
    "z = advertising.Sales\n",
    "\n",
    "ax.scatter(x, y, z, c='r', marker='o')\n",
    "ax.plot_surface(B1, B2, Z, rstride=10, cstride=5, alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('Radio')\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylabel('TV')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_zlabel('Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.434672600Z"
    }
   },
   "outputs": [],
   "source": [
    "azim=widgets.FloatSlider(min=-180, max=180, step=1, value=-60)    \n",
    "elev=widgets.FloatSlider(min=-180, max=360, step=1, value=30)   \n",
    "\n",
    "#ax.set_axis_off()\n",
    "@interact(elev=elev, azim=azim)\n",
    "def view(elev, azim):\n",
    "    ax.view_init(elev, azim)\n",
    "    #ax.azim=azim\n",
    "    #ax.elev=elev\n",
    "    display(ax.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur cette figure, il semble que l'on ait une déviation à la linéarité. En effet lorsque le budget est surtout affecté à l'un des pédicteurs, on sur-estime les ventes, alors que lorsque le budget est réparti, on a plutôt tendance à sous-estimer. Ceci suggère un comportment non-linéaire et même une *synergie* ou une *interaction* entre les prédicteurs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.437914200Z"
    }
   },
   "outputs": [],
   "source": [
    "ax.view_init(elev=26, azim=36)\n",
    "display(ax.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle linéaire que nous avons considéré juqu'ici *découple* l'effet des variables entre-elles. En d'autres termes, on considère que l'effet d'ajouter du budget sur le poste TV est complètement indépendant du budget déjà engagé sur radio (et réciproquement). Ceci n'est pas nécessairement exact. En effet, il est possible qu'investir sur l'un des postes infuence le rendement du second. Par exemple, il est possible qu'investir sur la radio augmente l'effet d'une dépense sur la TV (la pente pour TV augmente avec Radio). En marketing, ceci est appelé un effet de synergie. \n",
    "Avec le modèle de départ,\n",
    "$$\n",
    "Sales \\sim \\beta_0 + \\beta_1 TV + \\beta_2 Radio,\n",
    "$$\n",
    "lorsqu'on augmente TV d'une unité, Sales augmente de $\\beta_1$, quelque soit le niveau de Radio.\n",
    "\n",
    "Une manière de modifier ce comportement pour rendre compte d'une éventuelle synergie est d'introduire un prédicteur pour un terme d'interaction sous la forme TV*Radio : \n",
    "$$\n",
    "Sales \\sim \\beta_0 + \\beta_1 TV + \\beta_2 Radio + \\beta_3 TV.Radio.\n",
    "$$\n",
    "L'effet se comprend aisément en ré-écrivant cette relation sous la forme\n",
    "$$\n",
    "Sales \\sim \\beta_0 + (\\beta_1+\\beta_3 Radio) TV + \\beta_2 Radio,\n",
    "$$\n",
    "qui montre bien que cette fois le coefficient de TV est directement lié à Radio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec R, il n'y a qu'à demander : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pour rappel les résultats sans ce terme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.442830700Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lmModel = lm(Sales ~ Radio+TV, data=advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Et avec le terme de synergie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.449618Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lmModel = lm(Sales ~ Radio+TV+Radio*TV, data=advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate donc que la RSE passe de 1.681 à 0.9435, et que le terme de synergie présente une $p$-value extrêmement faible. Ceci indique donc à la fois l'existence d'une synergie, la pertinence de ce terme, et l'effet très important en terme de réduction de la RSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En R, il est encore possible de spécifier les termes d'interaction par une formulation comme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.453836600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lmModel = lm(Sales ~ (Radio+TV)^2, data=advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "### Non linéarités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.456607900Z"
    }
   },
   "outputs": [],
   "source": [
    "##%%R -o auto\n",
    "#auto=read.csv(file = \"http://www-bcf.usc.edu/~gareth/ISL/Auto.csv\")\n",
    "#summary(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.461462900Z"
    }
   },
   "outputs": [],
   "source": [
    "##%%R \n",
    "#write.csv(auto, file = \"Auto.csv\", row.names=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.464799Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "auto = read.csv(\"Auto.csv\",na.strings = \"?\")\n",
    "auto = na.omit(auto)\n",
    "summary(auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va chercher à prédire mpg (*gas mileage in miles per gallon*) en fonction de la puissance *horsepower* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.468995800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lm.fit = lm(mpg ~ horsepower, data=auto)\n",
    "summary(lm.fit)\n",
    "plot(auto$horsepower, auto$mpg, col = \"blue\", pch = 4)\n",
    "abline(lm.fit, lwd = 3, col = \"red\")\n",
    "plot(lm.fit, which=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.473078600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lm.fit = lm(mpg ~ horsepower + I(horsepower^2), data=auto)\n",
    "#\n",
    "plot(auto$horsepower, auto$mpg, col = \"blue\", pch = 4)\n",
    "minMax = range(auto$horsepower)\n",
    "xvals = seq(minMax[1], minMax[2], len = 100) \n",
    "# Use predict based on a dataframe containing 'horsepower'\n",
    "yvals = predict(lm.fit, newdata = data.frame(horsepower=xvals))\n",
    "lines(xvals, yvals,type=\"l\", col=\"red\", lw=2)\n",
    "#plot(lm.fit, which=1)\n",
    "summary(lm.fit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A un ordre plus élevé, on peut utiliser la fonction `poly` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.477188300Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lm.fit = lm(mpg ~ poly(horsepower,5), data=auto)\n",
    "#\n",
    "plot(auto$horsepower, auto$mpg, col = \"blue\", pch = 4)\n",
    "minMax = range(auto$horsepower)\n",
    "xvals = seq(minMax[1], minMax[2], len = 100) \n",
    "# Use predict based on a dataframe containing 'horsepower'\n",
    "yvals = predict(lm.fit, newdata = data.frame(horsepower=xvals))\n",
    "lines(xvals, yvals,type=\"l\", col=\"red\", lw=2)\n",
    "#plot(lm.fit, which=1)\n",
    "print(paste(\"R2=\",summary(lm.fit)$r.sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.480550200Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lm.fit = lm(mpg ~ (horsepower+weight+acceleration)^3, data=auto)\n",
    "#\n",
    "summary(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.484562500Z"
    }
   },
   "outputs": [],
   "source": [
    "# RESTART KERNEL HERE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display, HTML, Image, Javascript\n",
    "from ipywidgets import interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python, en utilisant `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.492561400Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "auto = pd.read_csv(\"Auto.csv\",na_values=\"?\").dropna()\n",
    "\n",
    "plt.scatter(auto.horsepower, auto.mpg, facecolors='None', edgecolors='k') \n",
    "sns.regplot(x=auto.horsepower, y=auto.mpg, ci=None, label='Linear', scatter=False)\n",
    "sns.regplot(x=auto.horsepower, y=auto.mpg, ci=None, label='Degree 2', order=2, scatter=False)\n",
    "sns.regplot(x=auto.horsepower, y=auto.mpg, ci=None, label='Degree 5', order=5, scatter=False)\n",
    "plt.legend()\n",
    "plt.ylim(5,55)\n",
    "plt.xlim(40,240);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas des variables catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est tout-à-fait possible de gérer des variables catégorielles (des facteurs). Pour cela, on crée des *dummy variables*  binaires qui couvrent tous les niveaux de la variable catégorielle initiale. Ainsi, si on a une variable numérique $X_1$ et une seconde variable $X_2$ à $L$ niveaux, on crée $p=\\lceil\\log_2 L\\rceil$ variables $X_{2i}$ et le modèle devient\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\sum_{i=1}^p \\beta_{2i} X_{2i} + \\epsilon\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic - Residual plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'hypothèse initiale utilisée pour bâtir le modèle est une hypothèse de linéarité et d'erreur de variance constante\n",
    "$$\n",
    "\\displaystyle{\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\ldots \\beta_p X_p + \\epsilon.\n",
    "}\n",
    "$$\n",
    "Afin de tester ces hypothèses, on peut soit utiliser une approche par tests d'hypothèse, soit une représentation dignostic. Parmi les représentations disponibles, le *residual plot* représente les résidus obtenus en fonction des valeurs prédites (*fitted*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hétéroscedasticité, non-linéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici quelques exemples de représentation qui peuvent intervenir (sur un exemple tiré de [Faraway: Linear Models with R]  (2005, p. 59)).\n",
    "\\begin{figure}[H]\n",
    "\\centerline{\\includegraphics[width=10cm]{residuals_example.png}}\n",
    "\\caption{\\label{fig:example_residual} Exemples de residual plots.}\n",
    "\\end{figure}\n",
    "![](residuals_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur l'exemple des données de publicité, on a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.496245600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "advertising = read.csv(file = \"Advertising.csv\")\n",
    "lmModel = lm(Sales ~ TV, data=advertising)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.496245600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(lmModel, which=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soit une indication d'un peu d'hétéroscedasticité (qui peut être éventuellement gérée en prenant $\\log(Y)$ ou $\\sqrt{Y}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.496245600Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "lmModel = lm(log(Sales) ~ TV, data=advertising)\n",
    "plot(lmModel, which=1)\n",
    "summary(lmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données aberrantes - *outliers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les outliers sont des données aberrantes, typiquement liées à un problème d'enregistrement (erreur sur un bit) par exemple. Elles présentent généralement une différence d'amplitude par rapport aux autres données. Une manière de détecter les outliers est de comparer les résidus à leur écart-type -- le rapport est alors le *studentized residual* (rapport d'une gaussienne à chi2) et de rejeter les rapports supérieurs à 3 en module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une illustration issue de  [An Introduction to Statistical Learning\n",
    "with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/) : \n",
    "\\begin{figure}[H]\n",
    "\\centerline{\\includegraphics[width=10cm]{example_studentized_residuals.png}}\n",
    "\\caption{\\label{fig:example_residual} Exemples de studentized residual.}\n",
    "\\end{figure}\n",
    "![](example_studentized_residuals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une manière de les obtenir en R : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.511136Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#studentized residual - typiquement, les valeurs doivent être comprises entre -3 et 3\n",
    "plot(fitted(lmModel),rstudent(lmModel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High leverage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le [*leverage*](https://en.wikipedia.org/wiki/Leverage_%28statistics%29) est une mesure de l'influence d'une variable particulière sur la régression. Voici une illustration où on ajoute un simple point qui a une influence non négligeable sur la régression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.519074900Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "set.seed(20)\n",
    "\n",
    "x1 = rnorm(50, mean=20, sd=3)\n",
    "y1 = 5 + .5*x1 + rnorm(20)\n",
    "\n",
    "x4 = c(x1, 30);        y4 = c(y1, 10)\n",
    "lm1=lm(y1~x1)\n",
    "lm2=lm(y4~x4)\n",
    "plot(y4~x4)\n",
    "points(30,10,pch=23, col=\"red\")\n",
    "abline(lm1,col=\"blue\")\n",
    "abline(lm2,col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le leverage représente l'influence de la donnée sur sa prédiction et est défini par\n",
    "$$\n",
    "h_{ii} = \\frac{\\partial \\hat{y}_i}{y_i}.\n",
    "$$\n",
    "On montre qu'il s'agit simplement du terme diagonal de la *hat-matrix* $H$ (\\ref{eq:hatmatrix}). \n",
    "\n",
    "Les données à fort leverage peuvent être détectées en calculant le distance de Cook, ou dans le plan (leverage, studentized residuals) qui est le 5e diagnostic fourni par `plot.lm(model)`. Le leverage peut être obtenu par `hatvalues(model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.522481100Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(lm1, which=5)\n",
    "plot(lm2, which=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colinéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque des variables explicatives sont corrélées, il est difficile de séparer l'influence des unes et des autres sur la variable dépendante. Ceci se traduit par une augmentation de la variance du résultat, donc du RSE, des p-values, etc. Bref, c'est néfaste. Cela peut aussi se comprendre en constatant que la corrélation entre les colonnes de $\\Xb$ va diminuer le conditionnement de $X^TX$ qui va devenir plus difficile à inverser. \n",
    "Pour juger de la colinéarité, on peut bien entendu examiner la matrice de corrélation. Ceci permet de repérer les variables franchement corrélées. Cependant, il peut aussi y avoir colinéarité lorsque plusieurs variables, 3, 4, 5 ou plus, sont corrélées entre elles ; dans ce cas, l'inspection directe de la matrice de corrélation est insuffisante. La stratégie consiste alors à essayer de faire une régression de chacune des variables en fonction de toutes les autres. On note ainsi $R^2_{X_j|X_{-j}}$ le R2 obtenu en effectuant la régression de $X_j$ vis-à-vis de l'ensemble des autres variables. Quand il y a colinéarité, ce dernier R2 est proche de 1. On définit alors un facteur le *VIF*, pour *Variance Inflation Factor*, par\n",
    "$$ \\label{eq:vif}\n",
    "VIF(\\hat{\\beta_j}) = \\frac{1}{1-R^2_{X_j|X_{-j}}}\n",
    "$$\n",
    "Sous R, on a directement accès à ce vif par `vif(model)` -- voir ce [post](https://beckmw.wordpress.com/2013/02/05/collinearity-and-stepwise-vif-selection/) à ce sujet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.527038700Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "library(car)\n",
    "advertising$corrvar = advertising$TV+6*advertising$Newspaper + rnorm(length(advertising$TV)) \n",
    "lmModel = lm(Sales ~ TV+Radio+Newspaper+corrvar, data=advertising)\n",
    "vif(lmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T17:09:07.533133700Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "cor(advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorqu'on détecte un VIF important, il faut alors rechercher soit à (i) supprimer les variables redondantes (ii) combiner les variables redondantes entre elles en une nouvelle variable. "
   ]
  }
 ],
 "metadata": {
  "author": "Introduction à la régression linéaire",
  "hide_input": false,
  "interactive_sols": {
   "cbx_id": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "ctrl-e",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "nav_menu": {},
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {
    "height": "460px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "951px",
   "left": "0px",
   "right": "20px",
   "top": "106px",
   "width": "184px"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "56cc523dbf4144f0ae18a9adfdbbc193": {
     "views": [
      {
       "cell_index": 73
      }
     ]
    },
    "921ed5d80f0e49c6a7a270bdc2977bd6": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "f1ae67d0752a448fa89f097490ff4fab": {
     "views": [
      {
       "cell_index": 45
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
